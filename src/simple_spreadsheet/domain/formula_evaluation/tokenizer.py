from typing import Union
from ..coordinates import Coordinates
from ..contents import Number
from .consts import Token, DECIMAL_SEPARATOR, SPECIAL_CHARS, FUNCTIONS, UNARY_OPERATORS, CLOSING_PARENTHESIS


class Tokenizer:
    def __init__(self) -> None:
        self._tokens: list[Token] = []
        self._decimal_separator = DECIMAL_SEPARATOR
        self._unary_operators = UNARY_OPERATORS
        self._special_chars = SPECIAL_CHARS
        self._functions = FUNCTIONS
        self._closing_parenthesis = CLOSING_PARENTHESIS

    def _is_valid_numeric_char(self, char: str) -> bool:
        """Checks if a character is a digit or the decimal separator."""
        return char.isdigit() or char == self._decimal_separator

    def _extract_number(self, expression: str, start_index: int, include_sign: bool = True) -> tuple[float, int]:
        """Extracts a numeric token from the expression."""
        num = ''
        decimal_separator_seen = False
        n = len(expression)
        i = start_index

        # Handle sign if needed
        if include_sign and i < n and expression[i] in self._unary_operators:
            num += expression[i]
            i += 1

        while i < n and self._is_valid_numeric_char(expression[i]):
            if expression[i] == self._decimal_separator:
                if decimal_separator_seen:
                    raise ValueError(
                        'A number contains multiple decimal separators')
                decimal_separator_seen = True
            num += expression[i]
            i += 1

        if num in self._unary_operators:  # Handle alone signs
            raise ValueError(f'Invalid number at position {start_index}')

        return Number(num), i

    def _extract_cell_or_function(self, expression: str, start_index: int) -> tuple[Union[str, Coordinates], int]:
        """Extracts a cell reference or function from the expression."""
        var = ''
        n = len(expression)
        i = start_index
        while i < n and (expression[i].isalpha() or expression[i].isdigit()):
            var += expression[i]
            i += 1

        if var.isalpha():  # All alphabetic characters
            upper_var = var.upper()
            if upper_var in self._functions:
                return upper_var, i
            raise ValueError(f'Invalid function "{
                             var}" at position {start_index}')
        return Coordinates.from_id(var), i

    def _is_binary_operator_context(self, prev_token: Token | None) -> bool:
        """
        Determines if the current context suggests a binary operator.
        Returns True if the previous token is a number, cell reference, or closing parenthesis.
        """
        return (prev_token is not None and
                (isinstance(prev_token, (Number, Coordinates)) or
                 (isinstance(prev_token, str) and prev_token == self._closing_parenthesis)))

    def tokenize(self, expression: str) -> list[Token]:
        """Tokenizes the given mathematical expression."""
        self._tokens = []
        n = len(expression)
        i = 0

        while i < n:
            char = expression[i]
            if char.isspace():
                i += 1
                continue

            prev_token = self._tokens[-1] if self._tokens else None

            if char in self._unary_operators:
                if self._is_binary_operator_context(prev_token):
                    self._tokens.append(char)
                    i += 1
                else:
                    try:
                        num, i = self._extract_number(
                            expression, i, include_sign=True)
                        self._tokens.append(num)
                    except ValueError as e:
                        if char in self._unary_operators:
                            self._tokens.append(char)
                            i += 1
                        else:
                            raise ValueError(
                                f'Invalid number format at position {i}') from e
            elif self._is_valid_numeric_char(char):
                num, i = self._extract_number(
                    expression, i, include_sign=False)
                self._tokens.append(num)
            elif char.isalpha():
                var, i = self._extract_cell_or_function(expression, i)
                self._tokens.append(var)
            elif char in self._special_chars:
                self._tokens.append(char)
                i += 1
            else:
                raise ValueError(f'Invalid character "{char}" at position {i}')

        return self._tokens

    def get_tokens(self) -> list[Token]:
        """Returns the tokens generated by the last call to tokenize."""
        return self._tokens
